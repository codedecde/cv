\roottitle{Research and Technical Projects}
\headedsection
  {\textbf{Weakly Supervised Attention Networks for Entity Recognition}}
  {\textsc{January 2019 - May 2019}} {%
  
    {
    Proposed a novel method for extracting entities in a weakly supervised framework, where the only labels pertaining to presence / absence of entites is known. The proposed method utilized processing of attention weights for extracting entity mentions from texts. The final model achieved strong results compared to other baseline methods for the task.
    }
}
\headedsection
  {\textbf{Semi Supervised Bilingual Lexicon Induction}}
  {\textsc{Spring 2018 - Fall 2018}} {%
  
    {
    \emph{Advised By Professor Graham Neubig and Professor Matthew Gormley at CMU} \\
    Proposed a novel way of investigating isomorphism between embedding spaces of different languages which showed strong correlations with predicting model performance for a variety of different models. Proposed a semi-supervised framework for aligning embedding spaces of different languages, obtaining state of the art results for 15 language pairs. Investigated the degree of isometry and the etymology of the languages, and showed that etymologically closer languages have more isomorphic embedding spaces.
    }
}
\headedsection
  {\textbf{Model Compression And Localization in RL for ATARI games}}
  {\textsc{Spring 2018 - Fall 2018}} {%
  
    {
    \emph{Course Project for Reinforcement Learning} \\
    Reduced the parameters of a DQN network for playing ATARI games to 3\% its original parameters, retaining performance using Knowledge Distillation. Also used max pooling as a proxy for an attention mechanism to visualize agent performance without any additional parameters.
    }
}
\headedsection
  {\textbf{MOQA: A Monte Carlo Search for Answers}}
  {\textsc{Spring 2018}} {%
  
    {
    \emph{Research Project Advised by Professor Barnab\`as P\'oczos} \\
    Worked on the task of KB completion by combining Deep RL with Monte Carlo Tree Search (MCTS). Used MCTS to generate supervision for the policy network, while also training the agent to estimate the value function used by MCTS. The resulting network yielded state of the art results on numerous benchmarking datasets.
    }
}

\headedsection
  {\textbf{Understanding and Answering Multi-sentence Recommendation Questions on Tourism}}
  {\textsc{Fall 2016}} {%
  
    {
    \emph{B.Tech Thesis under Prof.\ Mausam and Prof.\ Parag Singla at IIT Delhi} \\
    Worked on answering multi-sentence blog post questions, leveraging partially annotated data. The proposed model used a CRF with neural features, using Constrained Conditional Inference for incorporating global constraints for inference.
    }
}
\headedsection
  {\textbf{DERP : Deep Evaluation for Response Predictions (Automated Dialogue Scoring)}}
  {\textsc{Fall 2016}} {%
  
    {
    \emph{Course Project in Advanced NLP at IIT Delhi} \\
        Tackled automated evaluation of responses from dialogue systems. Exploited the thread structure of Reddit to generate context, response, alternate response triplets. Then proposed and trained a novel model to differentiate between relevant and randomly sampled negative responses. The final model achieved a zero shot correlation of 0.45 with human scores on the Ubuntu dataset.
    }
  }